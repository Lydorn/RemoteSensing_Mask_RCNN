{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE_SHAPES                [[64 64]\n",
      " [32 32]\n",
      " [16 16]\n",
      " [ 8  8]\n",
      " [ 4  4]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [ 0.1  0.1  0.2  0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  256\n",
      "IMAGE_MIN_DIM                  256\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [256 256   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.002\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [ 123.7  116.8  103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           buildings\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              2\n",
      "RPN_BBOX_STD_DEV               [ 0.1  0.1  0.2  0.2]\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TRAIN_ROIS_PER_IMAGE           128\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STPES               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "Loading weights  resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "Weights successfully loaded\n",
      "Preparing datasets\n",
      "Training network heads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Error processing image {'mask_path': 'data/processed/val/gt/kitsap32.0000.0004.png', 'path': 'data/processed/val/images/kitsap32.0000.0004.png', 'name': 'kitsap32.0000.0004', 'source': 'buildings', 'id': 259}\n",
      "Traceback (most recent call last):\n",
      "  File \"../Mask_RCNN/model.py\", line 1523, in data_generator\n",
      "    load_image_gt(dataset, config, image_id, augment=augment, use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"../Mask_RCNN/model.py\", line 1148, in load_image_gt\n",
      "    mask = utils.minimize_mask(bbox, mask, config.MINI_MASK_SHAPE)\n",
      "  File \"../Mask_RCNN/utils.py\", line 436, in minimize_mask\n",
      "    m = scipy.misc.imresize(m.astype(float), mini_shape, interp='bilinear')\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/scipy/misc/pilutil.py\", line 480, in imresize\n",
      "    im = toimage(arr, mode=mode)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/scipy/misc/pilutil.py\", line 299, in toimage\n",
      "    cmin=cmin, cmax=cmax)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/scipy/misc/pilutil.py\", line 90, in bytescale\n",
      "    cmin = data.min()\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/numpy/core/_methods.py\", line 29, in _amin\n",
      "    return umr_minimum(a, axis, None, out, keepdims)\n",
      "ValueError: zero-size array to reduction operation minimum which has no identity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading masks for image 259\n",
      "Loading masks for image 245\n",
      "\n",
      "Starting at epoch 0. LR=0.002\n",
      "\n",
      "Checkpoint Path: /notebooks/RemoteSensing_Mask_RCNN/logs/buildings20171115T1437/mask_rcnn_buildings_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "self.keras_model.fit_generator()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/conda/lib/python3.5/site-packages/keras/engine/training.py:2039: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading masks for image 637\n",
      "Loading masks for image 560\n",
      "Epoch 1/40\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%run -i 'train.py'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
